\section{Motivation}

Many industrial and scientific projects suffer from platform or language dependent representation of their core data structures. These problems often cause software engineers to stick with outdated tools or even programming languages, thus causing a lot of frustration. This does not only increase the burden of hiring new project members, but can ultimately cause a project to die unnecessarily.

The approach presented in this paper provides means of platform and language independent specification of serializable data structures and therefore a safe way to let old tools of a tool suite talk to the knew ones, without even the need of recompiling the old ones. We set out to design a new language, because we believe, that the best language a programmer can use to write a new tool, is the language that he likes the most. We also hat the strict requirement to provide a solution that can describe an intermediate representation with stable parts that can be used for decades and unstable parts that may change on a daily basis, until it is know how the transported data has to be shaped.

In order to achieve this goal, we introduce two new concepts:

The first one is an easy to use specification language for data structures providing simple data types like integers and strings, abstract data types like sets and maps, type safe pointers, extension points and single inheritance. The specification language is modular allowing for more readable specifications.

The second one is a formalized mapping of specified types to a bitwise representation of stored objects. The mapping is very compact and therefore scalable, easy to understand and therefore easy to bind to a new language. It does encode the type system and can therefore provide a maximum of upward and downward compatibility, while maintaining type safety at the same time. It allows for a maximum of safety when it comes to manipulating data unknown to the generated interface, while maintaining high decoding and encoding speeds\footnote{The serialization and deserialization operations are linear in the size of the input/output file.}.

In contrast to other serialization formats such as \gls{xml}, the serializable data can not be viewed or modified with a text editor. This however does not mean, that it is not human readable, because one can provide a human usable editor to edit arbitrary \gls{skill} files.

An improvement over \gls{xml} is, that the reflective usage of stored data is expected to be quite rare, because the binding generator is able to generate an interface that ensures type safety of modifications and provides a nice integration into the target language. This leads to a situation, where it is possible to use files containing data of arbitrary types. If the data stored in the file is not used by a client, he does not have to pay for it with execution time or memory. It is also not required for a client to know the whole intermediate representation of a tool suite, but only the parts he is going to use in order to achieve his goals.

The expected file sizes range from 1 MiB to 2 GiB, while having virtually no relevant numerical limits in the file size\footnote{There are practical limits, such as Java having array lengths limited to ~$2^{31}$ or current file systems having a maximum file size limit that is roughly equivalent to the size of a file completely occupied by objects with a single field of a single byte. There will also be problems with raw I/O-Performance for very large files and an implementation of a binding generator, which can handle files not storable in the main memory is a tricky thing to do.}. Please note, that the skill file format is a lot more compact then equivalent \gls{xml} files would be.
It is expected, that files contain objects of hundreds of types with thousands of instances each. If a type in such a file would contain in average three pointers, the file size would still be around a mega byte, which is due to a very compact representation of stored data. This will also lead to high load and store performance, because the raw disk speed is expected to be the limiting factor.


\subsection{Scientific Contributions}

This section is a very concise representation of contributions, that in part have already been mentioned above and in parts, will be mentioned much later.

The suggested serialization format and serialization language offer all of the following features at the same time:
\begin{itemize}
 \item a small footprint and therefore high decoding speeds
 \item a fully reflective type encoding
 \item type safe storage of pointers both to known and unknown types\footnote{I.e. regular references and annotations.}
 \item the specification language is modular\footnote{I.e. it can be distributed over many files.} and easy to use
 \item no tool using a common intermediate representation has to know the complete specification. It is even possible to strip away or add individual fields of commonly used types.
 \item the coding is platform and language independent
 \item the coding offers a maximum of downward \textbf{and} upward compatibility
 \item a programmer is communicating through a generated interface, which allows programmers knowing nothing about skill to interact with it, ensures type safety easily. It also allows programmers to write tools in the language they know the best\footnote{This is a problem especially in the scientific community, where many researchers work on similar problems but on completely different tools.}
 \item stored data, that is never needed by a tool, will never be touched
\end{itemize}

Any of the arguments above have already been made in various contexts \todo{cite, cite, cite; llvm tutorial ``llvm and perl'', platform independent javabytecode, IDL, ada serialization, custom binary formats}, but there is, to the best of our knowledge, no solution bringing all these demands together into a single product that does the job automatically.


\subsection{Related Work}

There are many approaches similar to ours, but most of them have a different focus. This section shall provide a concise list of related approaches. For potential users of \gls{skill}, this might also present alternatives superior for individual use cases.

\subsection*{XML}

\gls{xml} is a file format. The main differences are:
\begin{itemize}
 \item[+] XML can be manipulated with a text editor\footnote{Whereas skill requires a special editor, which will be provided by us eventually.}.
 \item[+] It is easier to write a libXML for a new language than to write a \gls{skill} backend\footnote{This is only a relevant point if no bindings exist for the language that you want to use.}.
 \item[-] XML is not an efficient encoding in terms of (disk-)space usage
 \item[-] XML is not type safe. This can be overcome partially by the \gls{xsd}.
 \item[-] XML does not provide references to other objects out of the box.
 \item[-] XML stores basically a tree, whereas a skill file contains an arbitrary amount of graphs of objects.
 \item[-] XML is usually accessed through a libXML, whereas \gls{skill} provides an API for each file format, thus a skill user does not require any \gls{skill} skills. To be fair, there are some language bindings, mainly for Java, which offer this benefit for XML as well.
\end{itemize}

\subsubsection*{XML Schema definitions}

The description language itself is more or less equivalent to most schema definition languages such as \gls{xsd} \todo{cite w3c}. The downside is that schema definitions have to operate on XML and can not directly be used with a binary format. There is also
no way to generate code for some client languages, including Ada, from a schema definition. For obvious reasons, there is no way to refer to other \gls{xml} documents from a \gls{skill} file. If this is a requirement, one might choose to stick with XML.

We feel that the \gls{skill} specification language is easier to use and existing specifications are a lot easier to read then \gls{xsd} files.

The type systems offered by \gls{skill} and \gls{xsd} are quite different, thus it might be worth a look which one better fits ones needs.

\subsubsection*{JAXP and xmlbeansxx}

For Java and C++, there are code generators, which can turn a XML schema file into code, which is able to deal with an XML in a similar way, as it is proposed by this work. In case of Java this is even in the standard library. The downside is, that, to our knowledge, this is only possible for Java and C++, thus it leaves us with portability issues. A minor problem of this approach is the lack of support for comment generation and the inefficient storage of serialized data.
An interesting observation is, that this approach deprives XML of its flexibility advantage over our solution.


\subsection*{ASN.1}

Is not powerful enough to fit our purpose.


\subsection*{IDL}

A concise description of IDL can be found in \cite{lamb87}. It seems not to be powerful enough and is certainly outdated. It is so old, that there are no bindings for any modern language. There is also not much documentation on further research on that area, thus creating a new approach with similar goals but modern techniques is in fact an option.

The published format is stated to be ASCII (\cite{lamb87} ยง2.4), which will cause similar efficiency problems as XML does, when large amounts of date are stored.


\subsection*{Apatche Thrift \& Protobuf}

Both lack subtyping. Protobuf has an overly complex notation language. Both seem to be optimized for network protocols, thus they do not have storage pools, which are the foundation of our serialization approach and an absolute requirement for some of our features, such as hints (see section \ref{hints}).


\subsection*{Java Bytecode, LLVM/IR and others}

Although Java Bytecode and the LLVM Intermediate Representation are hand crafted formats, they served as a guiding example in many ways.


\subsection*{Language Specific}

Language specific is language specific and can therefore not be used to interface between subsystems written in different programming languages, without a lot of effort. Our aim is clearly a language independent and easy to use serialization format.


\subsection*{Language Interfaces}
Language Interfaces do not permit serialization capabilities. Most language only provide interfaces for C, with varying quality and varying degree of automation. A significant problem are interfaces between languages with different memory models.

Interfacing between languages with different type systems and memory models over a common C interface can be very inefficient.
